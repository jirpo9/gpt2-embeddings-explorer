# 游 Quick Start Guide

## Rychl칠 spu코t캩n칤 za 3 minuty

### 1. Sta쬰n칤 projektu
```bash
git clone https://github.com/jirpo9/gpt2-embeddings-explorer.git
cd gpt2-embeddings-explorer
```

### 2. Instalace
```bash
pip install torch transformers
```

### 3. Spu코t캩n칤
```bash
python src/gpt2_embeddings.py
```

## Prvn칤 kroky

Po spu코t캩n칤 uvid칤te:
```
GPT-2 Embeddings Explorer
==================================================

Na캜ten model: gpt2
Velikost slovn칤ku: 50,257
Dimenze embedding콢: 768
Max. d칠lka sekvence: 1024

--------------------------------------------------

Zadejte text k anal칳ze (nebo 'q' pro ukon캜en칤): 
```

### Vyzkou코ejte tyto p콏칤klady:

1. **Jednoduch칳 text:**
   ```
   Hello, world!
   ```

2. **캛esk치 v캩ta:**
   ```
   Dobr칳 den, jak se m치te?
   ```

3. **Technick칳 text:**
   ```
   Machine learning uses neural networks.
   ```

4. **Emoji a speci치ln칤 znaky:**
   ```
   Python 游냀 is awesome! 
   ```

## Co uvid칤te?

Pro ka쬯칳 token dostanete:
- Jak byl text rozd캩len na tokeny
- Hodnoty embedding콢 (prvn칤ch 5)
- Normy vektor콢
- Pr콢m캩rn칳 embedding cel칠ho textu

## Dal코칤 p콏칤klady

Spus콘te uk치zkov칳 skript s pokro캜il칳mi p콏칤klady:
```bash
python examples/example_usage.py
```

## Pot콏ebujete pomoc?

- Otev콏ete issue na GitHubu
- Pod칤vejte se do README.md pro detailn칤 dokumentaci
- Zkontrolujte requirements.txt pro v코echny z치vislosti

---
游눠 **Tip:** Model se p콏i prvn칤m spu코t캩n칤 stahuje (~500MB), bu캞te trp캩liv칤!